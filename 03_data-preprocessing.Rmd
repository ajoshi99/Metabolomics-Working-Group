---
title: "3. Data pre-processing"
author: "Anu Joshi"
date: "May 18, 2019"
output:
  html_document:
    keep_md: yes
    theme: united
    highlight: tango
---

```{r include = FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE, 
                      comment = "", 
                      tidy = TRUE)

library(readr)                  # faster reading and writing csv files
library(dplyr)                  # data manipulation
library(magrittr)               # pipe operator
library(tibble)                 # row and data manipulation

df0 <- read_csv(here("data", "2_metabolite-clean.csv")) 
```
<br>


Dataset has samples (459 observations) in rows and covariates (1308 metabolites + 6 variables) in columns. 

_Note_: If you would like to remove data that has >30% missing values, use the filtered dataset. 

```{r results='hide', message=FALSE}
# extract all covariates to merge later
# 459 observations of 6 variables
df_var <- df0[, c(1:6)]


# remove covariates for the preprocessing steps
# use Assay as sample identifier in rownames
# 459 observation of 1308 metabolites
df <- 
  df0[, -c(2:6)] %>%
    column_to_rownames(var = "Assay")
```
<br> 


**1. Data imputation**    

Missing values in the dataset can be due to two major reasons - either the metabolites are absent or they are below the limit of detection (LOD). The missing data is Missing Not At Random (MNAR) so we should impute the missing values instead of completely removing it from the analysis. <br>

The dataset has `r `sum(is.na(df))` missing datapoints and it is therefore not a statistically viable option to remove the missing data without introducing censoring bias. 
<br> 


Using the minimum value of the metabolite divided by the square root of 2 for data imputation. <br>

```{r impute1, results='hide'}
# Step 1: create a dummy copy of the dataset
df_impute <- df

# Step 2: impute missing values with minimum/sqrt(2) 
for(i in 1:ncol(df_impute)){
  df_impute[is.na(df_impute[,i]), i] <- min(df_impute[, i]/sqrt(2), na.rm = TRUE)
}

# Step 3: check for missing values
# verify that all NAs have been replaced
sum(is.na(df_impute))

# Step 4: Save file
df_impute0 = df_impute %>% 
    rownames_to_column(var = "Assay") %>%
    merge(df_var, ., by = "Assay")
write_csv(df_impute0, here("data", "3_metabolite-Imp.csv"))
```

<br>
Other methods to consider for data imputation:      
* Use the minimum value/minimum metabolite abundance value                  
* kNN (k-Nearest Neighbors)         
* [No-Skip kNN algorithm](https://link.springer.com/article/10.1007/s11306-018-1451-8) to estimate missing metabolite abundances  
<br>


**2. Volume Normalization**       

We have one sample (RW10351 M) that had their sample extracted at a $60 \mu l$ while the rest of the samples were measured at $85 \mu l$. This can affect the overall abundance value produced by the LC-MS analysis. All normalization methods assume that the signal intensities scale linearly with the metabolite concentration. We are extending this idea and assuming that the metabolite signal intensities scale linearly with the sample volume. 

```{r normalize-data}
# Step 1: create a dummy copy of the dataset
df_impute_scale <- df_impute

# Step 2: Volume Normalizatin
df_impute_scale["RW10351 M", ] <- (df_impute_scale["RW10351 M", ]/60)*85

# Step 3: Save file
df_impute_scale0 = df_impute_scale %>% 
    rownames_to_column(var = "Assay") %>%
    merge(df_var, ., by = "Assay")
```

```{r include=FALSE}
write_csv(df_impute_scale0, here("data", "3_metabolite-VolNormImp.csv"))
```

